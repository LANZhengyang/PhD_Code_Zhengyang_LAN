{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f1670b-0066-44bc-a076-4769e9e2d473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_575841/2820489161.py:68: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  R_data = pd.read_csv('DataPC - Right.csv', header=None)\n",
      "/tmp/ipykernel_575841/2820489161.py:72: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  L_data = pd.read_csv('DataPC - Left.csv', header=None)\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([35, 89]))\n",
      "(array([0., 1.]), array([ 6, 14]))\n",
      "(array([0., 1.]), array([18, 45]))\n",
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 56.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhengyang/anaconda3/envs/env_gait3/lib/python3.9/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.utils import gait_dataloader\n",
    "from utils.utils import init_model,  patients_idx_to_cycles_idx, find_cycles_idx_by_patient_idx\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.utils import init_model,accuracy_end_to_end, GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import Lime, LimeBase\n",
    "from captum._utils.models.linear_model import SkLearnLinearRegression, SkLearnLasso\n",
    "from captum.attr._core.lime import get_exp_kernel_similarity_function\n",
    "\n",
    "def load_dataset_v1(dir_dataset,channel_first=True,flatten=True,shuffle=False,random_state=0):\n",
    "    index = [0,1,2,3,4,5,6,7,8,9,14,15,16,17,18,19,20,21,22,23,24,29]\n",
    "    \n",
    "    npzfile = np.load(dir_dataset + 'RightPC.npz')\n",
    "    \n",
    "    x_train_all = npzfile['Input']\n",
    "    y_train = npzfile['Output']\n",
    "    y_train = np.ravel(y_train)\n",
    "    x_train = x_train_all[:,:,index]\n",
    "    if channel_first:\n",
    "        x_train = x_train.transpose(0,2,1)\n",
    "    \n",
    "    npzfile = np.load(dir_dataset + 'LeftPC.npz')\n",
    "    x_val_all = npzfile['Input']\n",
    "    y_val = npzfile['Output']\n",
    "    y_val = np.ravel(y_val)\n",
    "    x_val = x_val_all[:,:,index]\n",
    "    if channel_first:\n",
    "        x_val = x_val.transpose(0,2,1)\n",
    "    \n",
    "    npzfile = np.load(dir_dataset + 'TD.npz')\n",
    "    x_test_all = npzfile['Input']\n",
    "    y_test = npzfile['Output']\n",
    "    y_test = np.ravel(y_test)\n",
    "    x_test = x_test_all[:,:,index]\n",
    "    if channel_first:\n",
    "        x_test = x_test.transpose(0,2,1)\n",
    "    \n",
    "    if flatten == True:\n",
    "        x_train = x_train.reshape([x_train.shape[0],-1])\n",
    "        x_val = x_val.reshape([x_val.shape[0],-1])\n",
    "        x_test = x_test.reshape([x_test.shape[0],-1])\n",
    "    \n",
    "    nb_classes = len(np.unique(np.concatenate((y_train, y_val, y_test), axis=0)))\n",
    "    \n",
    "    return x_train, y_train ,x_val, y_val, x_test, y_test, nb_classes\n",
    "\n",
    "dataset = \"archives/AQM/TDvsPC_new_no_shuffle/\"\n",
    "\n",
    "x_R, y_R ,x_L , y_L, x_TD, y_TD, nb_classes = load_dataset_v1(dataset,channel_first=True,flatten=False,shuffle=False,random_state=0)\n",
    "\n",
    "X_d = np.concatenate([x_R,x_L,x_TD])\n",
    "# X_d = X_d.reshape([len(X_d),-1])\n",
    "y_d = np.concatenate([y_R,y_L,y_TD])\n",
    "import  pandas as pd\n",
    "\n",
    "R_data = pd.read_csv('DataPC - Right.csv', header=None)\n",
    "R_idx = R_data[2].to_numpy()\n",
    "\n",
    "\n",
    "L_data = pd.read_csv('DataPC - Left.csv', header=None)\n",
    "L_idx = L_data[2].to_numpy()\n",
    "L_idx = L_idx + R_idx[-1]\n",
    "\n",
    "TD_data = pd.read_csv('DataTD - By Subject.csv', header=None)\n",
    "TD_idx = TD_data[2].to_numpy()\n",
    "TD_idx = TD_idx + L_idx[-1]\n",
    "\n",
    "cycle_end_idx = np.concatenate([R_idx,L_idx,TD_idx])\n",
    "cycle_end_idx\n",
    "\n",
    "patient_index_range = np.arange(len(R_idx)+len(L_idx)+len(TD_idx))\n",
    "patient_class = np.concatenate([np.ones(len(R_idx)+len(L_idx)), np.zeros(len(TD_idx))])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(patient_index_range, patient_class, test_size=0.4, stratify=patient_class,random_state=0)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test,y_test, test_size=0.75, random_state=0, stratify=y_test)\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(np.unique(y_val,return_counts=True))\n",
    "print(np.unique(y_test,return_counts=True))\n",
    "\n",
    "\n",
    "\n",
    "classifer = init_model(model_name='ResNet').load('new_train_lrR_ET_TDvsCPu_full_5_original_weight_ResNet/model-epoch=04-val_loss=0.96-val_accuracy=0.92.ckpt')\n",
    "classifer.predict(X_d[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e7cb94-68b3-4775-9a58-fb8c41a56c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_d[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164ea1b-bfef-413e-977e-634d98a08c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
